{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emtkD1MICQtL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxhdImrjDJCP"
      },
      "outputs": [],
      "source": [
        "calls = pd.read_csv('/content/drive/MyDrive/United data set/callsf0d4f5a.csv')\n",
        "reason = pd.read_csv('/content/drive/MyDrive/United data set/reason18315ff.csv')\n",
        "sentiment = pd.read_csv('/content/drive/MyDrive/United data set/sentiment_statisticscc1e57a.csv')\n",
        "customers = pd.read_csv('/content/drive/MyDrive/United data set/customers2afd6ea.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRj6aD2dXCal",
        "outputId": "fad5d2b2-c932-4252-a56f-9b5ef9f4c9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw-QkFPgF_Ql"
      },
      "outputs": [],
      "source": [
        "# existing reasons\n",
        "reasons1 = reason['primary_call_reason'].unique()\n",
        "reason['primary_call_reason'] = reason['primary_call_reason'].str.strip()\n",
        "reason['primary_call_reason'] = reason['primary_call_reason'].replace('\\s+', ' ', regex=True)\n",
        "reasons2 = reason['primary_call_reason'].unique()\n",
        "print('first',reasons1, len(reasons1))\n",
        "print('second',reasons2, len(reasons2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA PREPROCESSING: REASONS\n",
        "As observed above we still have duplicates, like\n",
        "'check in': 'check-in';'post flight': 'post-flight'; 'products and services': 'products & services' and 'voluntary cancel' must be 'voluntary cancellation' (for better presentation)."
      ],
      "metadata": {
        "id": "fBtjmCVN_P1r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJdjiQNPL0jb"
      },
      "outputs": [],
      "source": [
        "# Converting all entries to lowercase to standardize case\n",
        "reason['primary_call_reason'] = reason['primary_call_reason'].str.lower()\n",
        "\n",
        "# Defining a dictionary for replacements (using lowercase keys)\n",
        "replacements = {\n",
        "    'check in': 'check-in',\n",
        "    'post flight': 'post-flight',\n",
        "    'products and services': 'products & services',\n",
        "    'products & services': 'products & services',\n",
        "    'voluntary cancel': 'voluntary cancellation',  # better presentation\n",
        "    'mileage plus': 'mileageplus',  # Combine if necessary\n",
        "}\n",
        "\n",
        "# Applying the replacements\n",
        "reason['primary_call_reason'] = reason['primary_call_reason'].replace(replacements)\n",
        "\n",
        "# Now get the unique values again\n",
        "reasons2 = reason['primary_call_reason'].unique()\n",
        "\n",
        "print('Updated unique reasons:', reasons2, len(reasons2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8CV92VXL35i"
      },
      "outputs": [],
      "source": [
        "# Unique reasons sorted alphabetically\n",
        "sorted_reasons = sorted(reason['primary_call_reason'].unique())\n",
        "print('Sorted unique reasons:', sorted_reasons, len(sorted_reasons))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing: Calls\n",
        "The calls table is cleaned.\n",
        "1. Missing values is checked.\n",
        "2. Duplicates are dropped\n",
        "3. Ensuring the data types\n",
        "4. Conversion to datetime type\n",
        "5. Invalid Call durations (call end before call start)\n",
        "6. Filling missing transcripts with a placeholder"
      ],
      "metadata": {
        "id": "nbk8RGqGAysz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking missing values\n",
        "print(calls.isnull().sum())"
      ],
      "metadata": {
        "id": "nYZGlN2yBIYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNE7wFEiDq5F"
      },
      "outputs": [],
      "source": [
        "# Checking missing values\n",
        "calls.isnull().sum()\n",
        "\n",
        "# Drop duplicates\n",
        "calls.drop_duplicates(inplace=True)\n",
        "\n",
        "# Ensuring the call_id, customer_id, agent_id are of correct data types\n",
        "calls['call_id'] = calls['call_id'].astype(str)\n",
        "calls['customer_id'] = calls['customer_id'].astype(str)\n",
        "calls['agent_id'] = calls['agent_id'].astype(str)\n",
        "\n",
        "# Converting datetime columns to datetime type\n",
        "calls['call_start_datetime'] = pd.to_datetime(calls['call_start_datetime'])\n",
        "calls['call_end_datetime'] = pd.to_datetime(calls['call_end_datetime'])\n",
        "calls['agent_assigned_datetime'] = pd.to_datetime(calls['agent_assigned_datetime'])\n",
        "\n",
        "# Checking for invalid or extreme duration values (e.g., end time before start time)\n",
        "invalid_calls = calls[calls['call_end_datetime'] < calls['call_start_datetime']]\n",
        "if not invalid_calls.empty:\n",
        "    print(\"Invalid call durations:\", invalid_calls)\n",
        "    # Handle invalid records (e.g., drop or investigate further)\n",
        "    calls = calls[calls['call_end_datetime'] >= calls['call_start_datetime']]\n",
        "\n",
        "\n",
        "# Filling missing transcripts with a placeholder\n",
        "calls['call_transcript'].fillna('No transcript available', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhNam-fiIckV"
      },
      "outputs": [],
      "source": [
        "print(calls.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHYfhvfEIhQN"
      },
      "outputs": [],
      "source": [
        "calls.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data preprocessing of Reasons**"
      ],
      "metadata": {
        "id": "XOfOyb2VFVVb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d36gGOj0JgZ5"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values before cleaning:\", reason.isnull().sum())\n",
        "\n",
        "# Drop duplicates if any\n",
        "reason = reason.drop_duplicates()\n",
        "\n",
        "# Ensure call_id is of the correct type\n",
        "reason['call_id'] = reason['call_id'].astype(str)\n",
        "\n",
        "# Clean primary_call_reason by normalizing text, trimming spaces, etc.\n",
        "reason['primary_call_reason'] = reason['primary_call_reason'].str.lower().str.strip()\n",
        "reason['primary_call_reason'] = reason['primary_call_reason'].replace({'&': 'and', '-': ' ', '\\s+': ' '}, regex=True)\n",
        "\n",
        "# Remove any special characters\n",
        "reason['primary_call_reason'] = reason['primary_call_reason'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
        "\n",
        "# Handle missing values in primary_call_reason\n",
        "reason['primary_call_reason'] = reason['primary_call_reason'].fillna('unknown reason')\n",
        "\n",
        "# Check and print unique call reasons after cleaning\n",
        "unique_reasons = reason['primary_call_reason'].unique()\n",
        "print(\"Cleaned unique call reasons:\", unique_reasons)\n",
        "\n",
        "# inconsistencies in call reasons\n",
        "reason['primary_call_reason'] = reason['primary_call_reason'].replace({\n",
        "    'voluntary cancel': 'voluntary cancellation',\n",
        "    'mileage plus': 'mileageplus',\n",
        "    'traveler updates': 'traveler update',\n",
        "    'check in': 'check-in',\n",
        "    'post flight': 'post-flight'\n",
        "})\n",
        "\n",
        "unique_reasons_after_correction = reason['primary_call_reason'].unique()\n",
        "print(\"Corrected unique call reasons:\", unique_reasons_after_correction)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing: Sentiment**\n",
        "1. Missing Values\n",
        "2. Removing Duplicates\n",
        "3. Data types are correct\n",
        "4. Clean 'agent_tone' and 'customer_tone' by normalizing text\n",
        "5. Missing Sentiment Value and Silence percentage is replaced by its median value\n"
      ],
      "metadata": {
        "id": "N4Zio_bVFfKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values before cleaning:\", sentiment.isnull().sum())\n",
        "\n",
        "# Drop duplicates\n",
        "sentiment = sentiment.drop_duplicates()\n",
        "\n",
        "# Ensure 'call_id' and 'agent_id' are of the correct types\n",
        "sentiment['call_id'] = sentiment['call_id'].astype(str)\n",
        "sentiment['agent_id'] = sentiment['agent_id'].astype(str)\n",
        "\n",
        "# Clean 'agent_tone' and 'customer_tone' by normalizing text (lowercase, trimming spaces)\n",
        "sentiment['agent_tone'] = sentiment['agent_tone'].str.lower().str.strip()\n",
        "sentiment['customer_tone'] = sentiment['customer_tone'].str.lower().str.strip()\n",
        "\n",
        "# missing tones by filling with 'neutral'\n",
        "sentiment['agent_tone'] = sentiment['agent_tone'].fillna('neutral')\n",
        "sentiment['customer_tone'] = sentiment['customer_tone'].fillna('neutral')\n",
        "\n",
        "# Check for invalid or extreme values in numeric columns\n",
        "print(\"Sentiment numeric summary:\")\n",
        "print(sentiment[['average_sentiment', 'silence_percent_average']].describe())\n",
        "\n",
        "# Cap extreme values in numeric columns\n",
        "# 'average_sentiment' stays between 0 and 1, and 'silence_percent_average' between 0 and 100\n",
        "sentiment['average_sentiment'] = sentiment['average_sentiment'].clip(lower=0, upper=1)\n",
        "sentiment['silence_percent_average'] = sentiment['silence_percent_average'].clip(lower=0, upper=100)\n",
        "\n",
        "# Handle missing sentiment values by replacing with median values\n",
        "sentiment['average_sentiment'] = sentiment['average_sentiment'].fillna(sentiment['average_sentiment'].median())\n",
        "sentiment['silence_percent_average'] = sentiment['silence_percent_average'].fillna(sentiment['silence_percent_average'].median())\n",
        "\n",
        "# Re-checking for missing values after cleaning\n",
        "print(\"Missing values after cleaning:\", sentiment.isnull().sum())\n"
      ],
      "metadata": {
        "id": "Hoth-k0BCBNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment.head(10)"
      ],
      "metadata": {
        "id": "Wxxa07ZjIs4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tone Mapping: Customer and Agent**\n",
        "Since there are only 5 values for tone and it has a hierarchy among them, it can be easily mapped to 5 integer values [-2,2]."
      ],
      "metadata": {
        "id": "A8eLUT7MHyb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a mapping for tone values\n",
        "tone_mapping = {\n",
        "    'polite': 2,\n",
        "    'calm': 1,\n",
        "    'neutral': 0,\n",
        "    'frustrated': -1,\n",
        "    'angry': -2\n",
        "}\n",
        "\n",
        "# Add the 'agent_tone_value' column by mapping the 'agent_tone' values to the corresponding numeric values\n",
        "sentiment['agent_tone_value'] = sentiment['agent_tone'].map(tone_mapping)\n",
        "\n",
        "# Add the 'customer_tone_value' column by mapping the 'customer_tone' values to the corresponding numeric values\n",
        "sentiment['customer_tone_value'] = sentiment['customer_tone'].map(tone_mapping)\n",
        "\n",
        "# If there are any tones not covered by the mapping, fill them with 0 (neutral)\n",
        "sentiment['agent_tone_value'] = sentiment['agent_tone_value'].fillna(0)\n",
        "sentiment['customer_tone_value'] = sentiment['customer_tone_value'].fillna(0)\n",
        "\n",
        "# Check the updated sentiment DataFrame\n",
        "print(sentiment[['agent_tone', 'agent_tone_value', 'customer_tone', 'customer_tone_value']].head())\n"
      ],
      "metadata": {
        "id": "S2Zm4GrLDlm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preprocessing: Customers**\n",
        "1. Missing Values\n",
        "2. Remove Duplicates\n",
        "3. Customer_id: Data type -> String and Remove extra spaces\n",
        "4. Missing data for elite_level_code: NaN = 0.0\n",
        "5. Ensuring elite_level_code data type\n"
      ],
      "metadata": {
        "id": "t-Qpg82uJAUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = customers.isnull().sum()\n",
        "print(\"Missing values before cleaning:\\n\", missing_values)\n",
        "\n",
        "# Drop duplicates\n",
        "customers = customers.drop_duplicates()\n",
        "\n",
        "# Ensure 'customer_id' is of the correct type (string)\n",
        "customers['customer_id'] = customers['customer_id'].astype(str)\n",
        "\n",
        "# Strip any extra spaces from 'customer_name' and ensure all names are in proper case\n",
        "customers['customer_name'] = customers['customer_name'].str.strip().str.title()\n",
        "\n",
        "# Handle missing 'elite_level_code' - Assuming NaN means non-elite (level 0), fill with 0.0\n",
        "customers['elite_level_code'] = customers['elite_level_code'].fillna(0.0)\n",
        "\n",
        "# Ensure 'elite_level_code' is of float type\n",
        "customers['elite_level_code'] = customers['elite_level_code'].astype(float)\n",
        "\n",
        "# Verify changes and check for missing values after cleaning\n",
        "print(\"Missing values after cleaning:\\n\", customers.isnull().sum())\n",
        "print(customers.head())"
      ],
      "metadata": {
        "id": "bRiRe2qaDwgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging all the data together for Analysis"
      ],
      "metadata": {
        "id": "7Gp7gwoPJN4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merging all the columns to get a merged Data\n",
        "merged_data = calls.merge(reason, on='call_id', how='left') \\\n",
        "                    .merge(sentiment, on='call_id', how='left') \\\n",
        "                    .merge(customers, on='customer_id', how='left')\n",
        "\n",
        "# View the merged DataFrame\n",
        "print(\"Merged DataFrame:\")\n",
        "print(merged_data.head())\n",
        "print(\"\\nColumns in Merged DataFrame:\")\n",
        "print(merged_data.columns)"
      ],
      "metadata": {
        "id": "JBVREHEuGwaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **AHT and AST calculation:**\n",
        "Average Handling Time and Average Speed Time are the two parameters which will be calculated from the given Formula.\n",
        "1. AHT = total_handle_time / total_calls\n",
        "2. AST = total_waiting_time / total_calls"
      ],
      "metadata": {
        "id": "Ghm8vw0eEB5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Call Duration in Minutes\n",
        "# Call Duration = AST + AHT\n",
        "merged_data['call_duration'] = (merged_data['call_end_datetime'] - merged_data['call_start_datetime']).dt.total_seconds() / 60  # duration in minutes\n",
        "\n",
        "# Calculate AHT\n",
        "# Calculate total handle time and total calls\n",
        "total_handle_time = merged_data['call_duration'].sum()  # Total handle time in minutes\n",
        "total_calls = merged_data['call_duration'].count()  # Total number of calls\n",
        "\n",
        "# Calculate AHT\n",
        "AHT = total_handle_time / total_calls\n",
        "\n",
        "\n",
        "# Calculate AST (in minutes)\n",
        "merged_data['waiting_time'] = (merged_data['agent_assigned_datetime'] - merged_data['call_start_datetime']).dt.total_seconds() / 60\n",
        "total_waiting_time = merged_data['waiting_time'].sum()  # Sum of waiting times in minutes\n",
        "total_calls = merged_data['waiting_time'].count()  # Total number of calls\n",
        "\n",
        "\n",
        "AST = total_waiting_time / total_calls\n",
        "\n",
        "\n",
        "print(f\"Average Speed to Answer (AST): {AST:.2f} minutes\")\n",
        "\n",
        "print(f\"Average Handle Time (AHT): {AHT:.2f} minutes\")\n"
      ],
      "metadata": {
        "id": "MjuMqYh3FQib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aht_data = merged_data.groupby('agent_id_x').agg(\n",
        "    total_calls=('call_id', 'count'),  # Count total calls\n",
        "    total_duration=('call_duration', 'sum')  # Total duration of all calls\n",
        ").reset_index()\n",
        "\n",
        "# Calculate AHT\n",
        "aht_data['AHT'] = aht_data['total_duration'] / aht_data['total_calls']  # This gives AHT in seconds\n",
        "\n",
        "merged_data = merged_data.merge(aht_data[['agent_id_x', 'AHT']], on='agent_id_x', how='left')\n",
        "\n",
        "print(merged_data.head())"
      ],
      "metadata": {
        "id": "Xh_2TfZcfdrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data.head()"
      ],
      "metadata": {
        "id": "tYDUFmF9fgG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_id_col = 'agent_id_x'"
      ],
      "metadata": {
        "id": "-CAJGqDVaUTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AHT and AST per agent"
      ],
      "metadata": {
        "id": "o0slW_3hMU-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AHT and AST per agent\n",
        "aht_ast_per_agent = merged_data.groupby(agent_id_col).agg({\n",
        "    'waiting_time': 'mean',  # AST per agent\n",
        "    'call_duration': 'mean',  # AHT per agent\n",
        "    'call_id': 'count'  # Total calls handled per agent\n",
        "}).reset_index().rename(columns={'waiting_time': 'AST', 'call_duration': 'AHT', 'call_id': 'total_calls'})\n",
        "\n",
        "print(aht_ast_per_agent)"
      ],
      "metadata": {
        "id": "gsBHKvrLMfal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AHT and AST per customer"
      ],
      "metadata": {
        "id": "igpVUPWLMHUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AHT and AST per customer\n",
        "aht_ast_per_customer = merged_data.groupby('customer_id').agg({\n",
        "    'waiting_time': 'mean',  # AST per customer\n",
        "    'call_duration': 'mean',  # AHT per customer\n",
        "    'call_id': 'count'  # Total calls handled per customer\n",
        "}).reset_index().rename(columns={'waiting_time': 'AST', 'call_duration': 'AHT', 'call_id': 'total_calls'})\n",
        "\n",
        "print(aht_ast_per_customer)"
      ],
      "metadata": {
        "id": "eMhRys2ga9qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AHT and AST per call reason"
      ],
      "metadata": {
        "id": "k0AXpJzOML3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AHT and AST per call reason\n",
        "aht_ast_per_reason = merged_data.groupby('primary_call_reason').agg({\n",
        "    'waiting_time': 'mean',  # AST per reason\n",
        "    'call_duration': 'mean',  # AHT per reason\n",
        "    'call_id': 'count'  # Total calls handled for each reason\n",
        "}).reset_index().rename(columns={'waiting_time': 'AST', 'call_duration': 'AHT', 'call_id': 'total_calls'})\n",
        "\n",
        "print(aht_ast_per_reason)"
      ],
      "metadata": {
        "id": "XEyv0BXsbE6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Heat Map of AST, AHT and Total Calls by Call Reason"
      ],
      "metadata": {
        "id": "sXXcrVrVMgVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a heatmap for AHT and AST\n",
        "plt.figure(figsize=(14, 8))\n",
        "heatmap_data = aht_ast_per_reason.set_index('primary_call_reason')[['AST', 'AHT', 'total_calls']]\n",
        "\n",
        "# Normalize values\n",
        "normalized_data = (heatmap_data - heatmap_data.min()) / (heatmap_data.max() - heatmap_data.min())\n",
        "\n",
        "sns.heatmap(normalized_data, annot=True, cmap='coolwarm', fmt='.2f', cbar_kws={'label': 'Normalized Values'})\n",
        "plt.title('Heatmap of AST, AHT, and Total Calls by Call Reason', fontsize=16)\n",
        "plt.xlabel('Metrics', fontsize=14)\n",
        "plt.ylabel('Primary Call Reason', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nDInRUqIhCeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Elite Customer Analysis**\n",
        "For elite customers, i.e. frequent flyers are identified as those whose elite_level_code ranks in the top 10% of all customers. To determine this, the 90th percentile was calculated of the elite_level_code values, which serves as the benchmark for defining elite status. Any customer with an elite_level_code above this threshold is classified as elite. This approach helps isolate the most valuable customers, allowing the airline to tailor premium services and rewards to enhance their overall experience."
      ],
      "metadata": {
        "id": "Cc_KpZEVMyBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers.dropna(subset=['elite_level_code'], inplace=True)\n",
        "# Calculate the 90th percentile for elite customers\n",
        "percentile_90 = customers['elite_level_code'].quantile(0.9)\n",
        "print(f\"The 90th percentile benchmark elite_value_code is: {percentile_90}\\n\")\n",
        "\n",
        "elite_customers = customers[customers['elite_level_code'] > percentile_90]\n",
        "\n",
        "elite_customers = elite_customers[['customer_id', 'customer_name', 'elite_level_code']].drop_duplicates()\n",
        "\n",
        "print(\"Elite Customers DataFrame:\")\n",
        "print(elite_customers)"
      ],
      "metadata": {
        "id": "5VkObgF5lAda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Percentage of Elite Customers of Total Customers"
      ],
      "metadata": {
        "id": "B2e84mK7P7Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of customers\n",
        "total_customers = len(customers)\n",
        "\n",
        "# Number of elite customers\n",
        "elite_customers_count = len(elite_customers)\n",
        "\n",
        "# Calculate percentage of elite customers\n",
        "elite_percentage = (elite_customers_count / total_customers) * 100\n",
        "\n",
        "print(f\"Percentage of Elite Customers: {elite_percentage:.2f}%\")"
      ],
      "metadata": {
        "id": "wdjoUOAqlOYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reason.head()"
      ],
      "metadata": {
        "id": "DMBliWknn1eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elite_customers_data = (\n",
        "    elite_customers\n",
        "    .merge(calls, on='customer_id', how='inner')\n",
        "    .merge(reason, on='call_id', how='inner')\n",
        "    .merge(sentiment, on='call_id', how='inner')\n",
        ")\n",
        "\n",
        "print(elite_customers_data)"
      ],
      "metadata": {
        "id": "k2FXh50dnoKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elite_customers_data.head()"
      ],
      "metadata": {
        "id": "P-KFBEUQoCKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elite_customers_data['call_start_datetime'] = pd.to_datetime(elite_customers_data['call_start_datetime'])\n",
        "elite_customers_data['agent_assigned_datetime'] = pd.to_datetime(elite_customers_data['agent_assigned_datetime'])\n",
        "elite_customers_data['call_end_datetime'] = pd.to_datetime(elite_customers_data['call_end_datetime'])\n",
        "\n",
        "# Calculate HT (Handling Time) and ST (Speed of Answer Time)\n",
        "elite_customers_data['HT'] = (elite_customers_data['call_end_datetime'] - elite_customers_data['call_start_datetime']).dt.total_seconds()\n",
        "elite_customers_data['ST'] = (elite_customers_data['agent_assigned_datetime'] - elite_customers_data['call_start_datetime']).dt.total_seconds()\n"
      ],
      "metadata": {
        "id": "LtMU-eQEyeld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elite Customer vs Reasons"
      ],
      "metadata": {
        "id": "7Y_S98UzTPwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate elite customer counts per reason\n",
        "elite_reason_counts = elite_customers_data['primary_call_reason'].value_counts()\n",
        "\n",
        "# Horizontal bar plot for elite customers per reason\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x=elite_reason_counts.values, y=elite_reason_counts.index, palette=\"viridis\")\n",
        "plt.title('Number of Elite Customers per Primary Call Reason', fontsize=16)\n",
        "plt.xlabel('Number of Elite Customers', fontsize=12)\n",
        "plt.ylabel('Primary Call Reason', fontsize=12)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ra8OgEWVs1NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the benchmark values; you can replace these with actual benchmark values\n",
        "ast_benchmark = 5  # Example value\n",
        "aht_benchmark = 10  # Example value\n",
        "\n",
        "# Box plot for AST\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=elite_customers_data['ST'])\n",
        "plt.axvline(ast_benchmark, color='r', linestyle='--', label='AST Benchmark')\n",
        "plt.title('Box Plot of AST for Elite Customers')\n",
        "plt.xlabel('AST')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Box plot for AHT\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=elite_customers_data['HT'])\n",
        "plt.axvline(aht_benchmark, color='r', linestyle='--', label='AHT Benchmark')\n",
        "plt.title('Box Plot of AHT for Elite Customers')\n",
        "plt.xlabel('AHT')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dm4XYI9Pt1wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Tone for Elite Customers"
      ],
      "metadata": {
        "id": "dIgTnPZsTeOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Average Call Duration (HT) by Agent Tone\n",
        "plt.subplot(2, 2, 1)\n",
        "sns.barplot(data=elite_customers_data, x='agent_tone', y='HT', estimator='mean', palette='viridis')\n",
        "plt.title('Average Handle Time by Agent Tone for Elite Customers')\n",
        "plt.xlabel('Agent Tone')\n",
        "plt.ylabel('Average Handle Time (minutes)')\n",
        "\n"
      ],
      "metadata": {
        "id": "zlliTKaMVfJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRcd_caWVqrT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}